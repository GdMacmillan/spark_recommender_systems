{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrameNaFunctions as DFna\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark as ps\n",
    "import os\n",
    "\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"building recommender\") \\\n",
    "            .getOrCreate()\n",
    "            \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read movies CSV\n",
    "movies_df = spark.read.csv('data/movies/movies.csv',\n",
    "                         header=True,       # use headers or not\n",
    "                         quote='\"',         # char for quotes\n",
    "                         sep=\",\",           # char for separation\n",
    "                         inferSchema=True)  # do we infer schema or not ?\n",
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line count: 9125\n"
     ]
    }
   ],
   "source": [
    "print(\"line count: {}\".format(movies_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read ratings CSV\n",
    "ratings_df = spark.read.csv('data/movies/ratings.csv',\n",
    "                         header=True,       # use headers or not\n",
    "                         quote='\"',         # char for quotes\n",
    "                         sep=\",\",           # char for separation\n",
    "                         inferSchema=True)  # do we infer schema or not ?\n",
    "ratings_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 100004 ratings from 671 users on 9066 movies.\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings_df.rdd\n",
    "\n",
    "numRatings = ratings.count()\n",
    "numUsers = ratings.map(lambda r: r[0]).distinct().count()\n",
    "numMovies = ratings.map(lambda r: r[1]).distinct().count()\n",
    "\n",
    "print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|movieId|count(rating)|\n",
      "+-------+-------------+\n",
      "|   1580|          190|\n",
      "|   2659|            3|\n",
      "|   3794|            5|\n",
      "|   3175|           65|\n",
      "|    471|           49|\n",
      "|   1088|           53|\n",
      "|   1342|           17|\n",
      "|   1645|           60|\n",
      "|   2366|           23|\n",
      "|   6620|           17|\n",
      "|   8638|           17|\n",
      "|  96488|            4|\n",
      "| 160563|            2|\n",
      "|   7982|            3|\n",
      "|   1238|           17|\n",
      "|   1959|           30|\n",
      "|    463|            7|\n",
      "|   2122|           11|\n",
      "|   1591|           15|\n",
      "|   5518|            1|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_counts = ratings_df.groupBy(col(\"movieId\")).agg(F.count(col(\"rating\")))\n",
    "movies_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show's .5 increment ratings being chosen with less frequency than whole number values. This is an indicator that perhaps people don't know they can rate in increments of .5. Perhaps this is more indicative of a interface problem with the website rather than the users actual opinion of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ratingsRDD = ratings_df.rdd.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "#                                      rating=float(p[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK let's get something working!\n",
    "First I will split the data in to a training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1, movieId=31, rating=2.5, timestamp=1260759144),\n",
       " Row(userId=1, movieId=1029, rating=3.0, timestamp=1260759179),\n",
       " Row(userId=1, movieId=1061, rating=3.0, timestamp=1260759182)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_RDD, validation_RDD, test_RDD = ratings_df.randomSplit([.6, .2, .2], seed=0L)\n",
    "# training_RDD = training_RDD.rdd.cache()\n",
    "# validation_for_predict_RDD = validation_RDD.rdd.map(lambda x: (x[0], x[1])).cache()\n",
    "# test_for_predict_RDD = test_RDD.rdd.map(lambda x: (x[0], x[1])).cache()\n",
    "training_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 5L\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = range(4, 12)\n",
    "errors = []\n",
    "err = 0\n",
    "tolerance = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.948992716752\n",
      "For rank 5 the RMSE is 0.948618374438\n",
      "For rank 6 the RMSE is 0.945806714537\n",
      "For rank 7 the RMSE is 0.953022789405\n",
      "For rank 8 the RMSE is 0.946677108696\n",
      "For rank 9 the RMSE is 0.956961948065\n",
      "For rank 10 the RMSE is 0.952181780456\n",
      "For rank 11 the RMSE is 0.950707813636\n",
      "The best model was trained with rank 6\n"
     ]
    }
   ],
   "source": [
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "def nan_as_0(x):\n",
    "    if math.isnan(x):\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "for rank in ranks:\n",
    "    als = ALS(maxIter=iterations, regParam=regularization_parameter, rank=rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "    model = als.fit(training_RDD)\n",
    "    predictions = model.transform(validation_RDD)\n",
    "#     predictions = predictions.withColumn(\"prediction\", nan_as_0(col(\"prediction\")))\n",
    "#     new_predictions = DFna(predictions).fill(2.5, ['prediction'])\n",
    "    new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(new_predictions)\n",
    "    errors.append(rmse)\n",
    "\n",
    "    print 'For rank %s the RMSE is %s' % (rank, rmse)\n",
    "    if rmse < min_error:\n",
    "        min_error = rmse\n",
    "        best_rank = rank\n",
    "print 'The best model was trained with rank %s' % best_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we will build a CrossValidator to evaluate over a range of hyper parameters\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# The Estimator we will be using is ALS\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# With 2 values for als.regParam and 8 values for als.rank,\n",
    "# this grid will have 2 x 8 = 16 parameter settings for CrossValidator to choose from.\n",
    "\n",
    "als = ALS(maxIter=iterations, regParam=regularization_parameter, rank=rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(als.rank, range(4, 12)) \\\n",
    "    .build()\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "crossval = CrossValidator(estimator=als,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rmse for optimal grid parameters with cross validation is: 0.950506349727\n"
     ]
    }
   ],
   "source": [
    "predictions = cvModel.transform(test_RDD)\n",
    "new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "rmse = evaluator.evaluate(new_predictions)\n",
    "print \"the rmse for optimal grid parameters with cross validation is: {}\".format(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_als = ALS(maxIter=10, regParam=0.1, rank=6, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "final_model = final_als.fit(training_RDD)\n",
    "final_pred = final_model.transform(test_RDD)\n",
    "final_pred = final_pred.filter(col('prediction') != np.nan)\n",
    "rmse = evaluator.evaluate(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
